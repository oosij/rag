{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f2e6e0-2b34-442a-b186-49cf7d79c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cookbook.chromadb.dev/core/filters/#less-than-or-equal\n",
    "# https://medium.com/@karanbhatia.kb/chromadb-and-timestamp-data-a-guide-to-efficient-storage-and-retrieval-336f5ef85a7f\n",
    "import chromadb\n",
    "import cx_Oracle\n",
    "#import pymysql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "#import fitz  # PyMuPDF\n",
    "import pdfplumber\n",
    "\n",
    "import re\n",
    "import os \n",
    "import openai\n",
    "import docx\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from kss import split_sentences  \n",
    "from konlpy.tag import Kkma\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1eb113d-1825-4b32-8142-90efd9972b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 한국어 \\nembeddings = HuggingFaceEmbeddings(\\n    model_name=\"jhgan/ko-sroberta-multitask\", \\n    model_kwargs={\\'device\\': \\'cpu\\'}, \\n    encode_kwargs={\\'normalize_embeddings\\': True}\\n) \\n\\n# 영어 \\nembeddings = HuggingFaceEmbeddings(\\n    model_name=\"sentence-transformers/all-MiniLM-L6-v2\", \\n    model_kwargs={\\'device\\': \\'cpu\\'},\\n    encode_kwargs={\\'normalize_embeddings\\': True}\\n)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  사전 재료 \n",
    "OPENAI_API_KEY = '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'\n",
    "openai.api_key  = OPENAI_API_KEY\n",
    "#model_name = 'gpt-3.5-turbo'\n",
    "model_name = 'gpt-4o'\n",
    "\n",
    "# OpenAI ada-002 임베딩 함수 설정\n",
    "embedder = OpenAIEmbeddingFunction(model_name=\"text-embedding-ada-002\")\n",
    "\n",
    "#p_template = \"\"\"\n",
    "#안녕?\n",
    "#\"\"\"\n",
    "\n",
    "#result = get_completion(p_template, model_name, temperature=0, verbose=False)\n",
    "#result\n",
    "\n",
    "'''\n",
    "# 한국어 \n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"jhgan/ko-sroberta-multitask\", \n",
    "    model_kwargs={'device': 'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ") \n",
    "\n",
    "# 영어 \n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "    model_kwargs={'device': 'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cce2af-ca4d-43f7-bfca-27ecb488de1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d4bea-0660-4ad2-a30b-0359d214b61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "391b9ea6-a7b1-4303-97bb-a7e514b77a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 폴더 경로안의 모든 pdf 파일 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5c7b5-2fe0-4221-9881-fba02ea81135",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = './data/sample'\n",
    "page_list, pdf_path_list = pdf_loader_by_folder(data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce58cf8-5e12-4487-9543-09a6b997fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c5348e-2732-4e4a-b235-704b50a398c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/sample\\\\BNK투자증권_포스코퓨처엠_20240409.pdf',\n",
       " './data/sample\\\\DS투자증권_포스코퓨처엠_20230428.pdf',\n",
       " './data/sample\\\\교보증권_포스코퓨처엠_20240202_003670_20190031_342.pdf',\n",
       " './data/sample\\\\상상인_기업분석_포스코퓨처엠_20240425.pdf',\n",
       " './data/sample\\\\신한투자증권_포스코퓨처엠_240426.pdf',\n",
       " './data/sample\\\\유안타증권_포스코퓨처엠_240507.pdf',\n",
       " './data/sample\\\\키움증권_포스코퓨처엠_240426.pdf',\n",
       " './data/sample\\\\포스코퓨처엠_IBK투자증권_20231025.pdf',\n",
       " './data/sample\\\\포스코퓨처엠_대신증권_20231025.pdf',\n",
       " './data/sample\\\\하나증권_포스코퓨처엠_20240426.pdf']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03dccafe-c9de-4501-8a4e-099c96317703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'2024/04/08\\\\n포스코퓨처엠 (003670)\\\\n기업분석 리포트\\\\n투자의견 매수\\\\n[유지]\\\\n목표주가(6M) 410,000원\\\\n[유지] 45.6%\\\\n현재주가 281,500원\\\\n2024/04/08\\\\n주식지표\\\\n시가총액 21,806십억원\\\\n52주최고가 598,000원\\\\n52주최저가 233,500원\\\\n상장주식수 7,746만주\\\\n자본금/액면가 39십억원/500원\\\\n60일평균거래량 43만주\\\\n60일평균거래대금 127십억원\\\\n외국인지분율 9.1%\\\\n자기주식수 4.4만주/0.1%\\\\n주요주주및지분율\\\\nPOSCO홀딩스 외 62.5%\\\\n국민연금공단 5.6%\\\\n주가동향\\\\n김현태\\\\n철강/화학\\\\nhtkim@bnkfn.co.kr\\\\n(02)3215-1592\\\\n2\\\\n2\\\\n1\\\\n1\\\\n6\\\\n1\\\\n6\\\\n1\\\\n6\\\\n(%0\\\\n0\\\\n0\\\\n0\\\\n0\\\\n2 3\\\\n)\\\\n/4 2 3 /8\\\\n포\\\\nK\\\\n스 코 퓨\\\\nO S P I\\\\n2 3 /1\\\\n처\\\\n1\\\\n엠\\\\n2 4 /3\\\\n하반기에는 실적 개선 + 원재료 수직계열화 시작\\\\n재고평가손 환입이 더해져 1Q 실적은 예상보다 양호할 전망\\\\n1Q 연결OP 355억원으로 예상보다 양호할 전망이다. 시장 성장 둔화와 ASP\\\\n하락으로 에너지소재의 본원 수익성은 낮을 것으로 예상되나, 23.4Q에 인식\\\\n된 양극재 재고평가손실 중 일부분이 환입되면서 헤드라인 손익은 예상을 상\\\\n회할 전망이다. 손실환입까지 반영한 양극재OP는 177억원 (OPM 2.6%), 음\\\\n극재는 소폭 적자 (OPM -1%)가 예상된다. 양극재 출하량은 qoq 개선되나\\\\nASP 하락으로 매출액은 전분기 수준으로 예상되고, 음극재는 인조흑연 초기\\\\n생산비용 등으로 저조한 수익성이 예상된다. 기초소재는 유가 상승에 따른\\\\n화성사업 손익 개선 등으로 안정적인 실적을 기록할 것으로 예상된다.\\\\n하반기에는 뚜렷한 실적 회복세 예상\\\\n2Q까지는 yoy 실적 모멘텀이 제한적이나, 하반기에는 뚜렷한 회복세가 예상\\\\n된다 (연결OP 3Q 598억원, 4Q 705억원 예상). 리튬 가격 급락이 촉발한 양\\\\n극재ASP 하락이 하반기에는 진정될 것으로 예상되기 때문이다. 양극재 가격\\\\n은 리튬 가격에 2분기 후행해서 변동되는데, 리튬 가격이 연초에 바닥을 찍\\\\n은 후 2~3월 반등했기 때문에 2Q말~3Q부터는 양극재 가격이 안정화될 전\\\\n망이다. 하반기 금리 인하까지 현실화된다면, 고객사의 재고 리빌딩과 전기차\\\\n구매수요 회복이 맞물려 실적이 빠르게 반등할 수 있을 것으로 예상된다.\\\\n투자의견 매수, 목표주가 41만원 유지\\\\n23년 하반기부터 본격화된 양극재 가격 하락은 올해 상반기를 기점으로 마무\\\\n리될 전망이다. 더불어 그룹사를 통한 원재료 소싱의 수직계열화는, 하반기부\\\\n터 점진적으로 시작돼 2025년에 본격화되며 Peers 대비 양극재 사업의 근원\\\\n적 경쟁력이 높아질 전망이다. 실적과 주가에 부담이었던 ASP 하락의 부정적\\\\n영향이 마무리되는 시점으로, 매수 접근을 추천한다.\\\\nF ig. 1: 포스코퓨처엠 연결재무제표 요약\\\\n    \\\\n 3,302 4,760 5,339 7,804 10,668\\\\n 166 36 207 383 538\\\\n 134 -16 220 396 527\\\\n 118 29 160 295 386\\\\n 1,527 371 2,060 3,808 4,980\\\\n -13.4 -75.7 455.3 84.9 30.8\\\\n 117.9 968.2 136.7 73.9 56.5\\\\n 5.6 11.8 8.7 7.8 6.9\\\\n 57.3 176.2 54.7 35.9 28.8 BNK투자증권 리서치센터\\\\n 4.9 1.2 6.6 11.1 12.9\\\\n07325 서울시 영등포구 여의대로 56\\\\n한화손해보험빌딩 10층\\\\n 0.2 0.1 0.1 0.2 0.3\\\\nwww.bnkfn.co.kr\\\\n자료: 포스코퓨처엠, BNK투자증권 / 주: K-IFRS 연결\\\\n표1. 포스코퓨처엠 1분기 실적 전망\\\\n       \\\\n매출액 1,156.6 1,135.2 1.9 1,145.8 0.9 1,196.9 (3.4)\\\\n영업이익 35.5 20.3 75.1 (73.7) 흑자 전환 28.2 26.0\\\\n세전이익 39.4 50.9 (22.5) (145.4) 흑자 전환 32.2 22.6\\\\n순이익 30.4 40.2 (24.5) (102.1) 흑자 전환 21.6 40.9\\\\n지배순이익 28.0 39.1 (28.5) (75.3) 흑자 전환 24.7 13.1\\\\n영업이익률 3.1 1.8 (6.4) 2.4\\\\n세전이익률 3.4 4.5 (12.7) 2.7\\\\n지배순이익률 2.4 3.4 (6.6) 2.1\\\\n자료: Dataguide, BNK투자증권 추정\\\\n표2. 포스코퓨처엠 실적 추정\\\\n           \\\\n별도 매출액 1,035 1,108 1,209 1,105 1,088 1,195 1,267 1,475 3,041 4,457 5,024\\\\n내화물/생석회 173 177 166 174 182 186 175 183 600 691 726\\\\n로재정비/공사 78 73 59 75 82 76 61 79 259 284 298\\\\n케미칼 86 81 89 89 92 86 95 95 445 345 369\\\\n음극재 68 56 52 46 51 54 64 71 216 222 241\\\\n양극재 630 722 843 720 680 792 871 1,047 1,521 2,915 3,390\\\\n매출 (yoy %) 59 54 27 54 5 8 5 34 57 47 13\\\\n내화물/생석회 7 22 15 18 5 5 5 5 11 15 5\\\\n로재정비/공사 20 11 10 (1) 5 5 5 5 24 10 5\\\\n케미칼 (20) (29) (28) (11) 7 7 7 7 32 (22) 7\\\\n음극재 51 21 (24) (18) (24) (4) 24 54 24 3 9\\\\n양극재 131 108 50 112 8 10 3 45 124 92 16\\\\n별도 OP 16.3 48.2 35.9 (65.3) 34.0 39.0 54.3 69.5 153 35 197\\\\n내화물/생석회 3.0 6.4 5.7 10.5 7.3 9.3 8.7 7.3 4 26 33\\\\n로재정비/공사 5.1 6.9 2.7 7.4 4.9 5.3 4.3 3.1 8 22 18\\\\n케미칼 (4.5) 1.4 3.2 4.5 4.6 3.5 3.8 3.8 11 4 16\\\\n음극재 0.2 2.5 1.5 (0.5) (0.5) 1.1 2.6 2.9 10 4 6\\\\n양극재 12.6 31.0 22.8 (87.2) 17.7 19.8 34.8 52.3 120 (21) 125\\\\nOPM (%) 1.6 4.3 3.0 (5.9) 3.1 3.3 4.3 4.7 5.0 0.8 3.9\\\\n내화물/생석회 1.7 3.6 3.4 6.0 4.0 5.0 5.0 4.0 0.6 3.7 4.5\\\\n로재정비/공사 6.5 9.5 4.6 9.8 6.0 7.0 7.0 4.0 3.1 7.8 5.9\\\\n케미칼 (5.3) 1.7 3.6 5.0 5.0 4.0 4.0 4.0 2.5 1.3 4.3\\\\n음극재 0.3 4.4 3.0 (1.0) (1.0) 2.0 4.0 4.0 4.7 1.7 2.5\\\\n양극재 2.0 4.3 2.7 (12.1) 2.6 2.5 4.0 5.0 7.9 (0.7) 3.7\\\\n연결 OP 20.3 52.1 37.1 (73.7) 35.5 41.5 59.8 70.5 166 36 207\\\\n연결 세전이익 50.9 51.8 26.6 (145.4) 39.4 44.9 62.7 72.9 134 (16) 220\\\\n연결 순이익 40.2 43.1 23.2 (102.1) 30.4 34.6 48.3 56.2 122 4 169\\\\n지배순이익 39.1 42.5 22.3 (75.3) 28.0 31.7 44.9 55.0 118 29 160\\\\n자료: 포스코퓨처엠, BNK투자증권 추정\\\\n2\\\\nFig. 2: PBR 밴드 차트 Fig. 3: PER 밴드 차트\\\\n자료: Dataguide, BNK투자증권 자료: Dataguide, BNK투자증권\\\\nFig. 4: 영업현금흐름 추이 및 전망 Fig. 5: Capex 추이 및 전망\\\\n자료: ValueWise, BNK투자증권 자료: ValueWise, BNK투자증권\\\\nFig. 6: Free Cash Flow 추이 및 전망 Fig. 7: 순차입금 추이 및 전망\\\\n자료: ValueWise, BNK투자증권 자료: ValueWise, BNK투자증권\\\\n3\\\\n(천 원 )\\\\n6 0 0\\\\n5 0 0\\\\n4 0 0\\\\n3 0 0\\\\n2 0 0\\\\n1 0 0\\\\n0\\\\n1 1\\\\n(십 억 원 )\\\\n8 0 0\\\\n6 0 0\\\\n4 0 0\\\\n2 0 0\\\\n0\\\\n(2 0 0 )\\\\n(4 0 0 )\\\\n(6 0 0 )\\\\n1\\\\n1\\\\n2\\\\n2\\\\n1 3\\\\n1 3\\\\n주\\\\n6\\\\n1 4\\\\n1 4\\\\n가\\\\n.0 X\\\\n1 5\\\\n1 5 1\\\\n1\\\\n영\\\\n6\\\\n6\\\\n업\\\\n1\\\\n1\\\\n현\\\\n7\\\\n7\\\\n금\\\\n1\\\\n2 .0 X\\\\n8 .0 X\\\\n1 8 1 9\\\\n흐 름\\\\n8 1 9 2 0\\\\n2 0\\\\n2 1\\\\n2 1\\\\n2 2\\\\n4 .0 X\\\\n1 0 .0 X\\\\n2 2 2 3\\\\n2 3 2 4\\\\n2\\\\n2\\\\n4\\\\n5\\\\n(천 원\\\\n6 0 0\\\\n5 0 0\\\\n4 0 0\\\\n3 0 0\\\\n2 0 0\\\\n1 0 0\\\\n0\\\\n(십 억\\\\n2 ,5 0\\\\n2 ,0 0\\\\n1 ,5 0\\\\n1 ,0 0\\\\n5 0\\\\n)\\\\n1\\\\n원\\\\n0\\\\n0\\\\n0\\\\n0\\\\n0\\\\n0\\\\n1\\\\n)\\\\n1 2\\\\n1 2\\\\n1\\\\n1\\\\n3\\\\n3\\\\n1\\\\n1\\\\n4\\\\n4\\\\n주\\\\n6\\\\n가\\\\n0 X\\\\n1 5\\\\n1 5\\\\n1 6\\\\n1 6\\\\n2 0 X\\\\n8 0 X\\\\n1 7 1 8 1 9\\\\nC a p e x\\\\n1 7 1 8 1 9 2\\\\n2\\\\n0\\\\n0\\\\n2 1\\\\n2 1\\\\n2 2\\\\n4 0\\\\n1 0\\\\n2 2\\\\n2 3\\\\nX\\\\n0 X\\\\n2 3\\\\n2 4\\\\n2\\\\n2\\\\n4\\\\n5\\\\n(십억원) (십억원)\\\\nFree Cash Flow 순차입금\\\\n500 7,000\\\\n6,000\\\\n0\\\\n5,000\\\\n(500) 4,000\\\\n3,000\\\\n(1,000) 2,000\\\\n1,000\\\\n(1,500)\\\\n0\\\\n(2,000) (1,000)\\\\n1213141516171819202122232425 1213141516171819202122232425\\\\n재무상태표 포괄손익계산서\\\\n           \\\\n 2,038 2,412 2,194 3,052 4,047  3,302 4,760 5,339 7,804 10,668\\\\n 281 390 270 344 429  2,967 4,503 4,876 7,046 9,625\\\\n 288 758 534 780 1,067  335 257 463 758 1,043\\\\n 870 917 1,028 1,503 2,055 률 10.1 5.4 8.7 9.7 9.8\\\\n비 2,600 3,923 5,665 7,284 8,325  169 221 256 375 506\\\\n 294 291 304 320 336  5.1 4.6 4.8 4.8 4.7\\\\n 2,098 3,359 5,095 6,705 7,735  166 36 207 383 538\\\\n 31 41 34 28 23 률 5.0 0.8 3.9 4.9 5.0\\\\n 4,637 6,335 7,859 10,336 12,372  258 173 479 779 1,013\\\\n 966 1,396 1,456 1,827 2,258  -32 -52 13 13 -10\\\\n 289 262 294 430 588  8 -34 -70 -104 -137\\\\n 203 352 352 352 352  -13 2 0 0 0\\\\n비 1,021 2,327 3,628 5,435 6,642 기타 -27 -20 83 117 127\\\\n 926 2,218 3,518 5,318 6,518  134 -16 220 396 527\\\\n 1,987 3,723 5,084 7,262 8,901 률 4.1 -0.3 4.1 5.1 4.9\\\\n 2,471 2,350 2,504 2,793 3,170  12 -21 51 91 121\\\\n 39 39 39 39 39  9.0 131.3 23.2 23.0 23.0\\\\n 1,455 1,457 1,457 1,457 1,457  122 4 169 305 406\\\\n 1,003 998 1,152 1,441 1,818  122 4 169 305 406\\\\n 2,651 2,611 2,775 3,074 3,471 률 3.7 0.1 3.2 3.9 3.8\\\\n 1,493 3,130 4,419 6,289 7,571  118 29 160 295 386\\\\n 672 2,489 4,121 5,905 7,088  118 -16 169 305 406\\\\n현금흐름표 주요투자지표\\\\n          \\\\n -61 -445 597 220 326  1,527 371 2,060 3,808 4,980\\\\n 122 4 169 305 406  31,992 30,412 32,396 36,127 40,992\\\\n 236 430 405 604 748  3,859 3,574 7,013 11,343 14,480\\\\n 92 138 272 396 475  300 250 300 500 800\\\\n -59 -157 -31 -30 -32  117.9 968.2 136.7 73.9 56.5\\\\n -365 -616 173 -464 -539  4.2 5.8 4.1 2.8 2.0\\\\n감소 -31 -481 224 -246 -286  5.6 11.8 8.7 7.8 6.9\\\\n감소 -403 -138 -112 -475 -552  46.6 100.4 40.1 24.8 19.4\\\\n증가 81 0 32 136 158 EV/ 57.3 176.2 54.7 35.9 28.8\\\\n -31 -37 -51 -91 -121  19.0 436.4 13.7 12.7 15.3\\\\n -55 -1,031 -1,999 -2,011 -1,514  0.2 0.1 0.1 0.2 0.3\\\\n증가 -659 -1,352 -2,000 -2,000 -1,500 증가율 66.0 44.2 12.2 46.2 36.7\\\\n감소 0 1 0 0 0 증가율 36.3 -78.4 477.4 85.1 40.2\\\\n순감 -7 -14 0 0 0  -11.8 -75.7 455.5 84.9 30.8\\\\n 336 1,592 1,283 1,865 1,273  -13.4 -75.7 455.5 84.9 30.8\\\\n 389 1,637 1,289 1,870 1,282  75.0 142.6 183.2 236.2 256.4\\\\n 1 3 0 0 0  56.3 119.9 159.2 204.6 218.1\\\\n -23 -24 -20 -24 -40 /자기자본 25.3 95.3 148.5 192.1 204.2\\\\n 209 108 -119 74 85  2.8 0.1 2.4 3.4 3.6\\\\n 281 390 270 344 429  4.9 1.2 6.6 11.1 12.9\\\\n -720 -1,797 -1,403 -1,780 -1,174  6.0 -0.3 2.9 4.0 4.5\\\\n자료: 감사보고서(12월 결산), BNK투자증권 리서치센터 주: K-IFRS 연결 기준, 2024/04/08 종가 기준\\\\n4\\\\n 및  변경 주가 및  변동 추이(2Y)\\\\n \\\\n  \\\\n  \\\\n포스코퓨처엠 22/01/26 보유 130,000원 -11.1 6.9\\\\n(003670) 22/04/25 보유 130,000원 -3.6 5.0\\\\n22/07/07 매수 130,000원 18.0 49.6\\\\n22/10/25 매수 260,000원 -10.4 59.2\\\\n23/04/28 매수 410,000원 -4.0 45.9\\\\n23/10/24 매수 410,000원 -25.6 -10.2\\\\n24/04/08 매수 410,000원 - -\\\\n5\\\\n(천6\\\\n0\\\\n4 0\\\\n2 0\\\\n원0\\\\n0\\\\n0\\\\n0\\\\n2\\\\n)\\\\n2 /4 2 2 /1 0\\\\n포\\\\n목\\\\n스\\\\n표\\\\n2\\\\n코 퓨\\\\n주 가\\\\n3 /4\\\\n처 엠\\\\n2 3\\\\n주\\\\n/1\\\\n가\\\\n0 2 4 /4\\\\n투자등급 (기업 은 향후 6개월간 추천일 종가 대비 해당 종목의 예상수익률을 의미함.)\\\\n\\\\n\\\\n\\\\n이 자료에 게재된 내용들은 본인의 의견을 정확하게 반영하고 있으며, 외부의 부당한 압력이나 간섭없이 작성되었음을 확인합니다. 자\\\\n료 제공일 현재 당사는 상기 회사가 발행한 주식을 1% 이상 보유하고 있지 않으며, 지난 1년간 상기 회사의 유가증권(DR, CB, IPO 등)\\\\n발행과 관련하여 주간사로 참여한 적이 없습니다. 자료제공일 현재 조사분석 담당자는 상기회사가 발행한 주식 및 주식관련사채에 대하\\\\n여 규정상 고지하여야 할 재산적 이해관계가 없으며, 추천의견을 제시함에 있어 어떠한 금전적 보상과도 연계되어 있지 않습니다. 당자\\\\n료는 상기 회사 및 상기회사의 유가증권에 대한 조사분석담당자의 의견을 정확히 반영하고 있으나 이는 자료제공일 현재 시점에서의\\\\n의견 및 추정치로서 실적치와 오차가 발생할 수 있으며, 투자를 유도할 목적이 아니라 투자자의 투자판단에 참고가 되는 정보제공을 목\\\\n적으로 하고 있습니다. 따라서 종목의 선택이나 투자의 최종결정은 투자자 자신의 판단으로 하시기 바랍니다. 본 조사분석자료는 당사\\\\n고객에 한하여 배포되는 자료로 어떠한 경우에도 당사의 허락없이 복사, 대여, 재배포될 수 없습니다. 이 자료에는 네이버에서 제공한\\\\n나눔글꼴이 적용되어 있습니다.\\\\n'\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_text = page_list[0] # 1, 2, 3, 9\n",
    "pdf_text\n",
    "#len(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986e9e5-12f4-4775-8caf-5171a8883070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cd6024-b20c-4bfc-b722-71bca65a307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_content_list = []\n",
    "\n",
    "target_pdf_list = []\n",
    "\n",
    "for p in range(len(page_list)):\n",
    "    pdf_conent = page_list[p]\n",
    "    path_ = pdf_path_list[p]\n",
    "    page_len = len(pdf_conent)\n",
    "    if page_len < 256 :\n",
    "        image_content_list.append([pdf_conent , path_])\n",
    "    else : \n",
    "        text = clean_text_by_pdf(pdf_conent)\n",
    "        pdf_text = prompt_clean_pdf_content(text, model_name)\n",
    "        target_pdf_list.append([pdf_text , path_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cf3b6e0-ecaf-496a-9966-77854e18be0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c53e8-8e29-4e8f-ba62-8a487748bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류검사\n",
    "for i in range(4):\n",
    "    print(image_content_list[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11f39e80-b566-48ae-9c64-ed810f009bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포스코퓨처엠의 2024년 1분기 연결 실적은 매출 1.1조원(YoY Flat, QoQ -1%), 영업이익 379억원(YoY +87%, QoQ 흑자전환), 지배주주순이익 602억원(YoY +54%, QoQ 흑자전환)으로 시장 기대치를 상회했다. 양극재 부문(매출 비중 64%)의 경우, 메탈 가격 하락으로 양극재 판가 QoQ -20% 하락했으나, 고객사 재고 축적 수요 증가하며 출하량이 QoQ +20% 증가함에 따라, 부문 매출은 YoY -1%, QoQ -2%로 큰 변화 없었다. 부문 수익성의 경우, 4분기에 재고평가손실 반영했던 미드니켈 제품이 출하되는 과정에서 최근 메탈 가격 상승 반영하여 재고평가손실 환입 인식함에 따라 영업이익률은 QoQ +14.5%p 상승한 3% 기록한 것으로 추정된다. 환입 효과 제외 시 영업이익률은 -3% 수준으로 추정된다. 음극재 부문(매출 비중 4%)은, 북미 및 아시아 신규 고객사향 제품 출하가 본격적으로 증가하며 부문 매출 QoQ +6% 증가했다. 다만, 유럽 전기차 수요 둔화로 YoY 기준으로는 -30% 감소했다. 전분기 대비 출하량이 증가하며 부문 영업이익률은 7%(QoQ +6.4%p)로 크게 개선됐다. 철강 기초 소재 부문(매출 비중 32%) 매출은 YoY Flat, QoQ -1%로 큰 변화 없었다. 한편, 전사 수익성은 재고 평가 손실 환입 효과로, QoQ +9.7%p 상승해 영업이익률 +3% 기록했다.\n",
      "\n",
      "2분기 연결 실적은 매출 1.1조원(YoY -9%, QoQ -5%), 영업이익 104억원(YoY -80%, QoQ -72%)으로 다소 부진할 전망이다. 양극재 부문의 경우, 유럽 전기차 수요 부진에 따른 미드니켈 양극재 공장 출하 부진 지속되며 부문 매출 YoY -18%, QoQ -12% 감소할 전망이다. 부문 수익성의 경우, 미드니켈 공장 고정비 부담 증가와 함께, 전분기 대비 재고평가손실 환입 금액이 감소하며 BEP 수준의 영업이익률 전망한다. 음극재 부문은 신규 고객사향 천연 흑연 제품 출하 지속 및 인조 흑연 제품 출하로 부문 매출 YoY +40%, QoQ +59% 증가 전망한다.\n",
      "\n",
      "포스코퓨처엠은 전방 수요 둔화를 고려해, 2026년 기준 양극재/전구체 CAPA 가이던스를 1년전 대비 각각 -11%/-10% 하향 조정하였다. 이에 따라 Valuation 기준 시점인 2020년대 후반 실적 추정치를 하향 조정하였다. 한편, 시장 성장률 둔화에 따른 Valuation factor 하락 반영해, 목표 주가 역시 40만원으로 하향 조정하였다. 배터리 섹터 전반적인 주가 조정 과정에서 포스코퓨처엠 단기 주가 역시 부진 불가피할 것으로 판단한다. 다만, 하반기 GM 신차 출시 및 Ultium Cells 가동률 상승 과정에서의 수혜 가장 큰 양극재 기업이라는 점과 천연 흑연 음극재의 북미 및 아시아 신규 고객사향 매출 증가 폭 가파르다는 점 고려할 때, 국내 배터리 기업 중 하반기 실적 개선 모멘텀 가장 강할 것으로 판단한다. 시가총액 20조원 내외에서 조정 시 매수를 권고한다.\n"
     ]
    }
   ],
   "source": [
    "print(target_pdf_list[9][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e8befc-2327-41d0-be98-464d7a79faa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3d6f14-c0c3-489c-a946-e317fbcb2b7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a938d21-513f-4efd-bb25-5fac8c995c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-19 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# 임시 날짜 선정\n",
    "date_string  = '2024-06-19'\n",
    "\n",
    "# 문자열을 datetime 객체로 변환\n",
    "date_object = datetime.strptime(date_string, '%Y-%m-%d')\n",
    "\n",
    "print(date_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa4539cc-b5d4-4830-bf93-ff27ed3ba3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f982e3-b1f4-4475-9ccc-a90909f5aaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e204b152-e208-47f4-bcc2-5c40750ab008",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "\n",
    "for r in range(len(target_pdf_list)):\n",
    "    p_text , p_path  = target_pdf_list[r]\n",
    "    in_data = [p_text, date_object, p_path]\n",
    "    result_list.append(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2c6887f-a3c6-4ff4-b4b8-ff0792d8eb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['포스코퓨처엠의 2024년 1분기 연결 실적은 매출 1.1조원(YoY Flat, QoQ -1%), 영업이익 379억원(YoY +87%, QoQ 흑자전환), 지배주주순이익 602억원(YoY +54%, QoQ 흑자전환)으로 시장 기대치를 상회했다. 양극재 부문(매출 비중 64%)의 경우, 메탈 가격 하락으로 양극재 판가 QoQ -20% 하락했으나, 고객사 재고 축적 수요 증가로 출하량이 QoQ +20% 증가하며 부문 매출은 YoY -1%, QoQ -2%로 큰 변화 없었다. 부문 수익성의 경우, 4분기에 재고평가손실 반영했던 미드니켈 제품이 출하되는 과정에서 최근 메탈 가격 상승 반영하여 재고평가손실 환입 인식함에 따라 영업이익률은 QoQ +14.5%p 상승한 3%를 기록한 것으로 추정된다. 환입 효과 제외 시 영업이익률은 -3% 수준으로 추정된다. 음극재 부문(매출 비중 4%)은 북미 및 아시아 신규 고객사향 제품 출하가 본격적으로 증가하며 부문 매출 QoQ +6% 증가했다. 다만, 유럽 전기차 수요 둔화로 YoY 기준으로는 -30% 감소했다. 전분기 대비 출하량이 증가하며 부문 영업이익률은 7%(QoQ +6.4%p)로 크게 개선됐다. 철강 기초 소재 부문(매출 비중 32%) 매출은 YoY Flat, QoQ -1%로 큰 변화 없었다. 전사 수익성은 재고 평가 손실 환입 효과로, QoQ +9.7%p 상승해 영업이익률 +3%를 기록했다.\\n\\n2분기 연결 실적은 매출 1.1조원(YoY -9%, QoQ -5%), 영업이익 104억원(YoY -80%, QoQ -72%)으로 다소 부진할 전망이다. 양극재 부문의 경우, 유럽 전기차 수요 부진에 따른 미드니켈 양극재 공장 출하 부진 지속되며 부문 매출 YoY -18%, QoQ -12% 감소할 전망이다. 부문 수익성의 경우, 미드니켈 공장 고정비 부담 증가와 함께, 전분기 대비 재고평가손실 환입 금액이 감소하며 BEP 수준의 영업이익률을 전망한다. 음극재 부문은 신규 고객사향 천연 흑연 제품 출하 지속 및 인조 흑연 제품 출하로 부문 매출 YoY +40%, QoQ +59% 증가 전망한다.\\n\\n포스코퓨처엠은 전방 수요 둔화를 고려해, 2026년 기준 양극재/전구체 CAPA 가이던스를 1년전 대비 각각 -11%/-10% 하향 조정하였다. 이에 따라 Valuation 기준 시점인 2020년대 후반 실적 추정치를 하향 조정하였다. 한편, 시장 성장률 둔화에 따른 Valuation factor 하락 반영해, 목표 주가 역시 40만원으로 하향 조정하였다. 배터리 섹터 전반적인 주가 조정 과정에서 포스코퓨처엠 단기 주가 역시 부진 불가피할 것으로 판단한다. 다만, 하반기 GM 신차 출시 및 Ultium Cells 가동률 상승 과정에서의 수혜 가장 큰 양극재 기업이라는 점과 천연 흑연 음극재의 북미 및 아시아 신규 고객사향 매출 증가 폭 가파르다는 점 고려할 때, 국내 배터리 기업 중 하반기 실적 개선 모멘텀 가장 강할 것으로 판단한다. 시가총액 20조원 내외에서 조정 시 매수를 권고한다.',\n",
       " datetime.datetime(2024, 6, 19, 0, 0),\n",
       " './data/sample\\\\하나증권_포스코퓨처엠_20240426.pdf']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c82477be-38da-467a-ae8f-ccf30a451043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 langchain 비교용 \n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = '',\n",
    "    chunk_size = 256,\n",
    "    chunk_overlap  = 50,\n",
    "    length_function = len,\n",
    "    is_separator_regex=True,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(result_list[0][0])\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f90152d7-2c21-4b85-8220-1d874d060777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'포스코퓨처엠 (003670)\\n기업분석 리포트\\n투자의견 매수\\n[유지]\\n목표주가(6M) 410,000원\\n[유지] 45.6%\\n현재주가 281,500원\\n\\n하반기에는 실적 개선 + 원재료 수직계열화 시작\\n재고평가손 환입이 더해져 1Q 실적은 예상보다 양호할 전망\\n1Q 연결OP 355억원으로 예상보다 양호할 전망이다. 시장 성장 둔화와 ASP 하락으로 에너지소재의 본원 수익성은 낮을 것으로 예상되나, 23.4Q에 인식된 양극재 재고평가손실 중 일부분이 환입되면서 헤'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6c4aed88-3a11-49c1-91ba-47b05ac01149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'분이 환입되면서 헤드라인 손익은 예상을 상회할 전망이다. 손실환입까지 반영한 양극재OP는 177억원 (OPM 2.6%), 음극재는 소폭 적자 (OPM -1%)가 예상된다. 양극재 출하량은 qoq 개선되나 ASP 하락으로 매출액은 전분기 수준으로 예상되고, 음극재는 인조흑연 초기 생산비용 등으로 저조한 수익성이 예상된다. 기초소재는 유가 상승에 따른 화성사업 손익 개선 등으로 안정적인 실적을 기록할 것으로 예상된다.\\n\\n하반기에는 뚜렷한 실적 회복세 예상\\n2'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b581c64e-78c0-4929-85cb-d69b66aef038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'적 회복세 예상\\n2Q까지는 yoy 실적 모멘텀이 제한적이나, 하반기에는 뚜렷한 회복세가 예상된다 (연결OP 3Q 598억원, 4Q 705억원 예상). 리튬 가격 급락이 촉발한 양극재ASP 하락이 하반기에는 진정될 것으로 예상되기 때문이다. 양극재 가격은 리튬 가격에 2분기 후행해서 변동되는데, 리튬 가격이 연초에 바닥을 찍은 후 2~3월 반등했기 때문에 2Q말~3Q부터는 양극재 가격이 안정화될 전망이다. 하반기 금리 인하까지 현실화된다면, 고객사의 재고'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "430c41ea-aab1-4f5b-b736-c6dfccc9066f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', 고객사의 재고 리빌딩과 전기차 구매수요 회복이 맞물려 실적이 빠르게 반등할 수 있을 것으로 예상된다.\\n\\n투자의견 매수, 목표주가 41만원 유지\\n23년 하반기부터 본격화된 양극재 가격 하락은 올해 상반기를 기점으로 마무리될 전망이다. 더불어 그룹사를 통한 원재료 소싱의 수직계열화는, 하반기부터 점진적으로 시작돼 2025년에 본격화되며 Peers 대비 양극재 사업의 근원적 경쟁력이 높아질 전망이다. 실적과 주가에 부담이었던 ASP 하락의 부정적 영향이 마'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "01d849dc-f609-43ba-a90d-e2c8250cd04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'부정적 영향이 마무리되는 시점으로, 매수 접근을 추천한다.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc1bf3-7176-4794-9e4d-2730a8095ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d9612f9f-9c5c-4eee-a15f-985463423430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f6f58813-5ea1-4ca7-80c8-7250e6008a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 청크 생성\n",
    "chunks_with_metadata = create_chunks_with_metadata_by_pdf(result_list)\n",
    "\n",
    "# 데이터를 불러와서 텍스트를 일정한 수로 나누고 구분자로 연결하는 작업\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size= 256, \n",
    "    chunk_overlap=50, \n",
    "    separator=\"\"\n",
    ")\n",
    "\n",
    "    # 텍스트 청크 생성 및 메타데이터 유지\n",
    "split_chunks_with_metadata = text_splitter.split_documents(chunks_with_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f52450c6-b1be-4cd5-896f-172ea8da7f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포스코퓨처엠 (003670)\n",
      "기업분석 리포트\n",
      "투자의견 매수\n",
      "[유지]\n",
      "목표주가(6M) 410,000원\n",
      "[유지] 45.6%\n",
      "현재주가 281,500원\n",
      "\n",
      "하반기에는 실적 개선 + 원재료 수직계열화 시작\n",
      "재고평가손 환입이 더해져 1Q 실적은 예상보다 양호할 전망\n",
      "1Q 연결OP 355억원으로 예상보다 양호할 전망이다. 시장 성장 둔화와 ASP 하락으로 에너지소재의 본원 수익성은 낮을 것으로 예상되나, 23.4Q에 인식된 양극재 재고평가손실 중 일부분이 환입되면서 헤\n"
     ]
    }
   ],
   "source": [
    "print(split_chunks_with_metadata[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "da385ac3-6eff-46bd-8168-4f3e79dbf06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 낮을 것으로 예상되나, 23.4Q에 인식된 양극재 재고평가손실 중 일부분이 환입되면서 헤드라인 손익은 예상을 상회할 전망이다. 손실환입까지 반영한 양극재OP는 177억원 (OPM 2.6%), 음극재는 소폭 적자 (OPM -1%)가 예상된다. 양극재 출하량은 qoq 개선되나 ASP 하락으로 매출액은 전분기 수준으로 예상되고, 음극재는 인조흑연 초기 생산비용 등으로 저조한 수익성이 예상된다. 기초소재는 유가 상승에 따른 화성사업 손익 개선 등으로 안정적인 \n"
     ]
    }
   ],
   "source": [
    "print(split_chunks_with_metadata[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0ad9068e-f0f0-42af-bf14-eae17b0c7ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조한 수익성이 예상된다. 기초소재는 유가 상승에 따른 화성사업 손익 개선 등으로 안정적인 실적을 기록할 것으로 예상된다.\n",
      "\n",
      "하반기에는 뚜렷한 실적 회복세 예상\n",
      "2Q까지는 yoy 실적 모멘텀이 제한적이나, 하반기에는 뚜렷한 회복세가 예상된다 (연결OP 3Q 598억원, 4Q 705억원 예상). 리튬 가격 급락이 촉발한 양극재ASP 하락이 하반기에는 진정될 것으로 예상되기 때문이다. 양극재 가격은 리튬 가격에 2분기 후행해서 변동되는데, 리튬 가격이 연초에 \n"
     ]
    }
   ],
   "source": [
    "print(split_chunks_with_metadata[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c013dd76-f651-440f-aab7-0ca21deb2f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기 때문이다. 양극재 가격은 리튬 가격에 2분기 후행해서 변동되는데, 리튬 가격이 연초에 바닥을 찍은 후 2~3월 반등했기 때문에 2Q말~3Q부터는 양극재 가격이 안정화될 전망이다. 하반기 금리 인하까지 현실화된다면, 고객사의 재고 리빌딩과 전기차 구매수요 회복이 맞물려 실적이 빠르게 반등할 수 있을 것으로 예상된다.\n",
      "\n",
      "투자의견 매수, 목표주가 41만원 유지\n",
      "23년 하반기부터 본격화된 양극재 가격 하락은 올해 상반기를 기점으로 마무리될 전망이다. 더불어 \n"
     ]
    }
   ],
   "source": [
    "print(split_chunks_with_metadata[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7831c719-dd92-496b-bdd1-ce45f1a30480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하반기부터 본격화된 양극재 가격 하락은 올해 상반기를 기점으로 마무리될 전망이다. 더불어 그룹사를 통한 원재료 소싱의 수직계열화는, 하반기부터 점진적으로 시작돼 2025년에 본격화되며 Peers 대비 양극재 사업의 근원적 경쟁력이 높아질 전망이다. 실적과 주가에 부담이었던 ASP 하락의 부정적 영향이 마무리되는 시점으로, 매수 접근을 추천한다.\n"
     ]
    }
   ],
   "source": [
    "print(split_chunks_with_metadata[4].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1ea701f-bff3-48ab-8fe9-cc64c5606d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포스코퓨처엠 (003670)\n",
      "기업분석 리포트\n",
      "투자의견 매수\n",
      "[유지]\n",
      "목표주가(6M) 410,000원\n",
      "[유지] 45.6%\n",
      "현재주가 281,500원\n",
      "\n",
      "하반기에는 실적 개선 + 원재료 수직계열화 시작\n",
      "재고평가손 환입이 더해져 1Q 실적은 예상보다 양호할 전망\n",
      "1Q 연결OP 355억원으로 예상보다 양호할 전망이다. 시장 성장 둔화와 ASP 하락으로 에너지소재의 본원 수익성은 낮을 것으로 예상되나, 23.4Q에 인식된 양극재 재고평가손실 중 일부분이 환입되면서 헤드라인 손익은 예상을 상회할 전망이다. 손실환입까지 반영한 양극재OP는 177억원 (OPM 2.6%), 음극재는 소폭 적자 (OPM -1%)가 예상된다. 양극재 출하량은 qoq 개선되나 ASP 하락으로 매출액은 전분기 수준으로 예상되고, 음극재는 인조흑연 초기 생산비용 등으로 저조한 수익성이 예상된다. 기초소재는 유가 상승에 따른 화성사업 손익 개선 등으로 안정적인 실적을 기록할 것으로 예상된다.\n",
      "\n",
      "하반기에는 뚜렷한 실적 회복세 예상\n",
      "2Q까지는 yoy 실적 모멘텀이 제한적이나, 하반기에는 뚜렷한 회복세가 예상된다 (연결OP 3Q 598억원, 4Q 705억원 예상). 리튬 가격 급락이 촉발한 양극재ASP 하락이 하반기에는 진정될 것으로 예상되기 때문이다. 양극재 가격은 리튬 가격에 2분기 후행해서 변동되는데, 리튬 가격이 연초에 바닥을 찍은 후 2~3월 반등했기 때문에 2Q말~3Q부터는 양극재 가격이 안정화될 전망이다. 하반기 금리 인하까지 현실화된다면, 고객사의 재고 리빌딩과 전기차 구매수요 회복이 맞물려 실적이 빠르게 반등할 수 있을 것으로 예상된다.\n",
      "\n",
      "투자의견 매수, 목표주가 41만원 유지\n",
      "23년 하반기부터 본격화된 양극재 가격 하락은 올해 상반기를 기점으로 마무리될 전망이다. 더불어 그룹사를 통한 원재료 소싱의 수직계열화는, 하반기부터 점진적으로 시작돼 2025년에 본격화되며 Peers 대비 양극재 사업의 근원적 경쟁력이 높아질 전망이다. 실적과 주가에 부담이었던 ASP 하락의 부정적 영향이 마무리되는 시점으로, 매수 접근을 추천한다.\n"
     ]
    }
   ],
   "source": [
    "print(split_chunks_with_metadata[0].metadata['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0ed754bf-01cc-4726-be1e-4e461ee32856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'포스코퓨처엠 (003670)\\n기업분석 리포트\\n투자의견 매수\\n[유지]\\n목표주가(6M) 410,000원\\n[유지] 45.6%\\n현재주가 281,500원\\n\\n하반기에는 실적 개선 + 원재료 수직계열화 시작\\n재고평가손 환입이 더해져 1Q 실적은 예상보다 양호할 전망\\n1Q 연결OP 355억원으로 예상보다 양호할 전망이다. 시장 성장 둔화와 ASP 하락으로 에너지소재의 본원 수익성은 낮을 것으로 예상되나, 23.4Q에 인식된 양극재 재고평가손실 중 일부분이 환입되면서 '"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_chunks_with_metadata[0].metadata['text'][0:255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd8360-8168-4608-9c16-54146459f5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f08765-daa1-4aad-b147-20d779b3bda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0a4f24a8-7782-4264-8287-5f56dc07fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT 용\n",
    "client = chromadb.PersistentClient()\n",
    "# 컬렉션 생성\n",
    "collection = client.create_collection(name=\"sample_gpt_2\", embedding_function=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5614afe0-aee0-4708-97da-a1d4c4250865",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.PersistentClient()\n",
    "collection = client.create_collection(name=\"sample\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9fb2e1cb-523a-4f69-a0f1-0781385be9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=sample_gpt_2)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cdcc9bb4-3d74-463d-9f29-7cd3b66fd799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=sample_gpt),\n",
       " Collection(name=VDB_add_test),\n",
       " Collection(name=sample)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = chromadb.PersistentClient()\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8a1a95cf-84dd-45a1-8187-4f4cdbd92b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 컬렉션 삭제\n",
    "collection_name = \"sample\"\n",
    "\n",
    "client.delete_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "aa97aea7-abaa-45db-b9be-3cc9be43146e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=VDB_add_test), Collection(name=sample)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 존재하는 컬렉션 목록 확인\n",
    "collections = client.list_collections()\n",
    "collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa067053-b5e4-4404-b0e1-d9279b34b4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "aa415896-7e80-46dc-a69a-5ed937d94fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for di in range(len(documents)):\n",
    "    cit_dic = documents[di].metadata['citation']\n",
    "    documents[di].metadata['citation'] = str(cit_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64318b-f849-44dc-a0fc-9c936678c770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "101aec28-365b-4072-931c-4c2b7e53a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromadb 에 맞게 형식 변환 : datetime -> timestamp(int) /   dict - > string\n",
    "\n",
    "documents = split_chunks_with_metadata\n",
    "documents = timestamp_convert(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5a017307-66a5-44de-9898-e11b5449809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포스코퓨처엠 (003670)\n",
      "기업분석 리포트\n",
      "투자의견 매수\n",
      "[유지]\n",
      "목표주가(6M) 410,000원\n",
      "[유지] 45.6%\n",
      "현재주가 281,500원\n",
      "\n",
      "하반기에는 실적 개선 + 원재료 수직계열화 시작\n",
      "재고평가손 환입이 더해져 1Q 실적은 예상보다 양호할 전망\n",
      "1Q 연결OP 355억원으로 예상보다 양호할 전망이다. 시장 성장 둔화와 ASP 하락으로 에너지소재의 본원 수익성은 낮을 것으로 예상되나, 23.4Q에 인식된 양극재 재고평가손실 중 일부분이 환입되면서 헤\n",
      "\n",
      "{'text': '포스코퓨처엠 (003670)\\n기업분석 리포트\\n투자의견 매수\\n[유지]\\n목표주가(6M) 410,000원\\n[유지] 45.6%\\n현재주가 281,500원\\n\\n하반기에는 실적 개선 + 원재료 수직계열화 시작\\n재고평가손 환입이 더해져 1Q 실적은 예상보다 양호할 전망\\n1Q 연결OP 355억원으로 예상보다 양호할 전망이다. 시장 성장 둔화와 ASP 하락으로 에너지소재의 본원 수익성은 낮을 것으로 예상되나, 23.4Q에 인식된 양극재 재고평가손실 중 일부분이 환입되면서 헤드라인 손익은 예상을 상회할 전망이다. 손실환입까지 반영한 양극재OP는 177억원 (OPM 2.6%), 음극재는 소폭 적자 (OPM -1%)가 예상된다. 양극재 출하량은 qoq 개선되나 ASP 하락으로 매출액은 전분기 수준으로 예상되고, 음극재는 인조흑연 초기 생산비용 등으로 저조한 수익성이 예상된다. 기초소재는 유가 상승에 따른 화성사업 손익 개선 등으로 안정적인 실적을 기록할 것으로 예상된다.\\n\\n하반기에는 뚜렷한 실적 회복세 예상\\n2Q까지는 yoy 실적 모멘텀이 제한적이나, 하반기에는 뚜렷한 회복세가 예상된다 (연결OP 3Q 598억원, 4Q 705억원 예상). 리튬 가격 급락이 촉발한 양극재ASP 하락이 하반기에는 진정될 것으로 예상되기 때문이다. 양극재 가격은 리튬 가격에 2분기 후행해서 변동되는데, 리튬 가격이 연초에 바닥을 찍은 후 2~3월 반등했기 때문에 2Q말~3Q부터는 양극재 가격이 안정화될 전망이다. 하반기 금리 인하까지 현실화된다면, 고객사의 재고 리빌딩과 전기차 구매수요 회복이 맞물려 실적이 빠르게 반등할 수 있을 것으로 예상된다.\\n\\n투자의견 매수, 목표주가 41만원 유지\\n23년 하반기부터 본격화된 양극재 가격 하락은 올해 상반기를 기점으로 마무리될 전망이다. 더불어 그룹사를 통한 원재료 소싱의 수직계열화는, 하반기부터 점진적으로 시작돼 2025년에 본격화되며 Peers 대비 양극재 사업의 근원적 경쟁력이 높아질 전망이다. 실적과 주가에 부담이었던 ASP 하락의 부정적 영향이 마무리되는 시점으로, 매수 접근을 추천한다.', 'wdate': '2024-06-19 00:00:00', 'pdf': './data/sample\\\\BNK투자증권_포스코퓨처엠_20240409.pdf', 'citation': {'start_p': 0, 'end_p': 255}, 'timestamp': 1718722800}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].page_content)\n",
    "print()\n",
    "print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cae67f70-b625-43c1-81b1-d60e1671b935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1ba284ce-0148-49df-932a-4f47ad252324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 19.163312673568726 seconds\n"
     ]
    }
   ],
   "source": [
    "# GPT 용 \n",
    "start_time = time.time()\n",
    "\n",
    "#documents = text_list\n",
    "\n",
    "ids = [str(i) for i in range(len(documents))]\n",
    "page_contents = [doc.page_content for doc in documents]\n",
    "metadatas = [doc.metadata for doc in documents]\n",
    "embeddings = embedding_function(page_contents)\n",
    "#collection.add(ids=ids, embeddings=embeddings, metadatas=metadatas, documents=page_contents)\n",
    "\n",
    "# 실행할 코드 블록 끝 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산 및 출력\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "20772136-d13e-495d-9d95-eff803fd7898",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(ids=ids, embeddings=embeddings, metadatas=metadatas, documents=page_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1531a2e9-341d-49a2-9abe-f3895192fd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0]) # gpt : 1536 ,   baai : 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b35f4585-f649-48a9-9b97-473bf94c4463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 11.223163843154907 seconds\n"
     ]
    }
   ],
   "source": [
    "## 로컬용 \n",
    "start_time = time.time()\n",
    "\n",
    "#documents = text_list\n",
    "\n",
    "ids = [str(i) for i in range(len(documents))]\n",
    "page_contents = [doc.page_content for doc in documents]\n",
    "metadatas = [doc.metadata for doc in documents]\n",
    "embeddings = embedding_function(page_contents)\n",
    "\n",
    "#collection.add(ids=ids, embeddings=embeddings, metadatas=metadatas, documents=page_contents)\n",
    "\n",
    "# 실행할 코드 블록 끝 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산 및 출력\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6fa7f2d3-1255-47e7-9aac-3d6cb62475b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87027e06-0364-4951-938b-c1825ecc0e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb4c9a6-3a7b-470b-8cb1-94740c7170a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=sample_gpt),\n",
       " Collection(name=VDB_add_test),\n",
       " Collection(name=sample),\n",
       " Collection(name=sample_gpt_2)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vdb 로드 \n",
    "client = chromadb.PersistentClient()\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00caeec5-7c5e-41c9-9a8a-8333c5b33b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt용 \n",
    "collection_name = 'sample_gpt_2'\n",
    "collection = client.get_or_create_collection(name=collection_name, embedding_function=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87e0c1c0-f82f-4c92-b864-d64cff6cffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'sample' 컬렉션 불러오기\n",
    "collection_name = 'sample'\n",
    "collection = client.get_or_create_collection(name=collection_name, embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b685e823-c0cd-4250-bd4b-3ac72f776474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include embeddings in the get method\n",
    "#vec1 = collection.get(include=['embeddings', 'documents', 'metadatas'])['embeddings'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44e7d5a2-8515-457d-82a7-c9cabcf9b36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1718377200, 1718809200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime(2024, 6, 15)\n",
    "end_date = datetime(2024, 6, 20)\n",
    "\n",
    "start_timestamp = int(start_date.timestamp())\n",
    "end_timestamp = int(end_date.timestamp())\n",
    "\n",
    "start_timestamp, end_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9335eb1c-6a35-4da3-bc94-91a0df698c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=sample_gpt_2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ac017ec-9f24-43ce-a996-4d9ef5bb9607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6b7b87f-cf28-4b53-9b7c-8f5b2e2bd21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N86 제품의 앞으로의 전망은 어떠한가?',\n",
       " '양극재 사업 수익성은 전망이 어떠한가?',\n",
       " '음극재 사업 수익성은 전망이 어떠한가?',\n",
       " '양극재 가격이 안정화될 것이라면 그 근거는 무엇인가?']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read the contents of the text file located at './data/query/질문.txt' and extract its contents into a list, with each line as a separate list element.\n",
    "\n",
    "# Define the file path\n",
    "file_path = './data/query/검색해야할질문리스트.txt'\n",
    "\n",
    "# Read the file and extract lines into a list\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Strip newline characters from each line\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "query_list = lines[:-1]\n",
    "query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fadfd426-7618-439d-9750-0f2d4836e545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N86 제품의 앞으로의 전망은 어떠한가?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_text = query_list[0] # 1은 그럴싸함 \n",
    "query_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f106518-5aae-448b-9c15-966b82298cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Kss]: Number of requested results 100 is greater than number of elements in index 72, updating n_results = 72\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[query_text],\n",
    "    where={\n",
    "        \"$and\": [\n",
    "            {\"timestamp\": {\"$gt\": start_timestamp}},\n",
    "            {\"timestamp\": {\"$lt\": end_timestamp}},\n",
    "            #{\"ticker\": \"DIS\"}\n",
    "        ]\n",
    "    },\n",
    "    n_results = 100 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5f622b-4039-4969-ac04-cc6d3e1b4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_n = list(set(results['documents'][0]))\n",
    "#doc_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94657bc0-6e17-4dc1-9b9e-cad1a8ccb4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranking\n",
    "sent_list = reranker_model(query_text, doc_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0656eaf8-c1ea-44ba-a847-6654783adf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 제품의 높은 원재료 비용으로 인한 마진 압박을 전망.\\n\\n투자의견 Buy, 목표주가 300,000원으로 하향. 전방 업황이 어려운 가운데 신제품 양산에 대한 수율 개선이 어려움으로 작용되고 있으나 GM의 견조한 전기차 출하량 전망에 따른 N86 증가와 수율 개선에 따른 안정적인 생산이 진행되고 있음. 인조흑연도 고객사와의 장기계약이 진행되고 있어 레퍼런스를 기반으로 신규 고객사 확대를 기대.',\n",
       " '4억원(YoY+21.3%), 영업이익 1,254억원(YoY+104.3%)을 전망. 가격하락과 전방수요 부진 영향이 지속적으로 반영될 것이며 유럽 고객향 비중이 많고 미드니켈 특성을 갖고 있는 N65 제품은 당분간 물량감소가 예상. 다만 N86제품은 GM의 24년 20~30만대의 판매량 전망에 따른 견조한 출하량 증가. 음극재는 판매량은 증가할 것으로 전망하나 인조흑연 제품의 높은 원재료 비용으로 인한 마진 압박을 전망.\\n\\n투자의견 Buy, 목표주가 300',\n",
       " '전망\\n\\n양극재. 유럽 EV 수요 둔화 지속, N86 단결정 수율의 완만한 개선으로 분기 출하량은 QoQ9% 증가에 그칠 예상. 유럽향 N65 판매량 부진을 북미(GM)향 N86 판매량 확대로 상쇄하나, 시장 기대치 대비 아쉬운 성장세\\n\\n음극재는 전분기와 유사한 실적, 기초소재는 비수기 영향으로 실적 부진 예상\\n\\n4분기 인건비 인상분 관련 일회성 비용 반영으로 전체 수익성은 부진할 전망']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f72baf00-3466-4f95-b8ef-3e54690006d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신은 투자 전문가입니다. 다음 보고서 내용을 기반으로 질문에 성실히 답변해주세요.\n",
      "\n",
      "질문:\n",
      "N86 제품의 앞으로의 전망은 어떠한가?\n",
      "\n",
      "보고서 내용:\n",
      "\n",
      "[1]  제품의 높은 원재료 비용으로 인한 마진 압박을 전망.\n",
      "\n",
      "투자의견 Buy, 목표주가 300,000원으로 하향. 전방 업황이 어려운 가운데 신제품 양산에 대한 수율 개선이 어려움으로 작용되고 있으나 GM의 견조한 전기차 출하량 전망에 따른 N86 증가와 수율 개선에 따른 안정적인 생산이 진행되고 있음. 인조흑연도 고객사와의 장기계약이 진행되고 있어 레퍼런스를 기반으로 신규 고객사 확대를 기대.\n",
      "[2] 4억원(YoY+21.3%), 영업이익 1,254억원(YoY+104.3%)을 전망. 가격하락과 전방수요 부진 영향이 지속적으로 반영될 것이며 유럽 고객향 비중이 많고 미드니켈 특성을 갖고 있는 N65 제품은 당분간 물량감소가 예상. 다만 N86제품은 GM의 24년 20~30만대의 판매량 전망에 따른 견조한 출하량 증가. 음극재는 판매량은 증가할 것으로 전망하나 인조흑연 제품의 높은 원재료 비용으로 인한 마진 압박을 전망.\n",
      "\n",
      "투자의견 Buy, 목표주가 300\n",
      "[3] 전망\n",
      "\n",
      "양극재. 유럽 EV 수요 둔화 지속, N86 단결정 수율의 완만한 개선으로 분기 출하량은 QoQ9% 증가에 그칠 예상. 유럽향 N65 판매량 부진을 북미(GM)향 N86 판매량 확대로 상쇄하나, 시장 기대치 대비 아쉬운 성장세\n",
      "\n",
      "음극재는 전분기와 유사한 실적, 기초소재는 비수기 영향으로 실적 부진 예상\n",
      "\n",
      "4분기 인건비 인상분 관련 일회성 비용 반영으로 전체 수익성은 부진할 전망\n",
      "\n",
      "답변:\n"
     ]
    }
   ],
   "source": [
    "#- 한글(korean)로만 답변해주세요.\n",
    "'''\n",
    "prompt_template = \"\"\"당신은 투자 전문가입니다. 이 문서의 주요 내용은 무엇입니까? 3가지 주요 내용을 요약해 주십시오.\n",
    "\n",
    "## 문서 내용:\n",
    "\n",
    "{doc_1}\n",
    "{doc_2}\n",
    "{doc_3}\n",
    "\n",
    "\n",
    "## 요약:\"\"\"\n",
    "\n",
    "'''\n",
    "\n",
    "#당신은 투자 전문가입니다. 다음 참고 내용을 기반으로 질문에 성실히 답변해주세요.\n",
    "#만약, 참고 내용에 관련 내용이 없을 경우 모른다고 대답해주세요. \n",
    "#답변은 반드시 한글(korean)으로 하십시오.\n",
    "\n",
    "\n",
    "#만약, 참고 내용에 관련 내용이 없을 경우 모른다고 대답해주세요. \n",
    "'''\n",
    "prompt_template = \"\"\"다음 참고 내용을 기반으로 질문에 성실히 답변해주세요.\n",
    "\n",
    "### 질문:\n",
    "{user_query}\n",
    "\n",
    "### 참고 내용:\n",
    "\n",
    "{doc_1}\n",
    "{doc_2}\n",
    "{doc_3}\n",
    "\n",
    "### 답변:\"\"\"\n",
    "'''\n",
    "\n",
    "prompt_template = \"\"\"당신은 투자 전문가입니다. 다음 보고서 내용을 기반으로 질문에 성실히 답변해주세요.\n",
    "\n",
    "질문:\n",
    "{user_query}\n",
    "\n",
    "보고서 내용:\n",
    "\n",
    "[1] {doc_1}\n",
    "[2] {doc_2}\n",
    "[3] {doc_3}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "\n",
    "doc_1 = sent_list[0]\n",
    "\n",
    "doc_2 = sent_list[1]\n",
    "\n",
    "doc_3 = sent_list[2]\n",
    "\n",
    "in_prompt = prompt_template.format(user_query = query_text, doc_1 = doc_1, doc_2 = doc_2,  doc_3 = doc_3 )\n",
    "print(in_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565865cb-4b7f-460d-a10c-4ece47605e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1b86bfa-acf4-4312-b34e-388a1822c799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[user msg] =  N86 제품의 앞으로의 전망은 어떠한가?\n",
      "\n",
      "[AI bot msg] =  \"안녕하세요! N86 제품은 향후 전망이 좋은 편입니다. GM과의 장기 계약을 통해 안정적으로 생산을 진행하고 있습니다. 또한, 유럽에서 N86의 판매량이 증가할 예정이어서 긍정적입니다. 하지만, 인조 흑연의 원자재 비용 압박은 여전히 문제입니다. 이에 따라 투자의견은 'Buy'로 하향 조정했습니다. 목표 주가는 300만원입니다. N65의 경우, 판매량 감소는 예상되나 북미향 판매량 증가로 이를 보완할 수 있을 것으로 보입니다. 유극재의 경우 전망치에 못 미치는 실적이 예상됩니다.\"\n",
      "\n",
      "이 답변은 다음 증권사 리포트 파일을 인용해서 가져왔습니다 :\n",
      "- 교보증권_포스코퓨처엠_20240202_003670_20190031_342.pdf 파일의 본문 길이 : 618에서 837까지 인용\n",
      "- 교보증권_포스코퓨처엠_20240202_003670_20190031_342.pdf 파일의 본문 길이 : 412에서 667까지 인용\n",
      "- 포스코퓨처엠_대신증권_20231025.pdf 파일의 본문 길이 : 1236에서 1451까지 인용\n",
      "time : 66.92252564430237\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# transformers의 로깅 설정을 조정하여 경고 메시지 억제\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "eos_c_token = \"<|end_of_text|>\"\n",
    "\n",
    "sys_msg = \"친절한 챗봇으로서 상대방의 요청에 최대한 자세하고 친절하게 답하자. 모든 대답은 한국어(Korean)으로 대답해줘.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": sys_msg},\n",
    "    ]\n",
    "\n",
    "\n",
    "start = time.time()  # 시작 시간 저장\n",
    "\n",
    "#user_input = input('[user msg] = ')\n",
    "\n",
    "user_input = in_prompt # 지침 \n",
    "\n",
    "user_msg = {\"role\": \"user\", \"content\": user_input}\n",
    "messages.append(user_msg)\n",
    "\n",
    "chat = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "prompt = chat\n",
    "\n",
    "response = inference_output(prompt)\n",
    "output = response.split(\"<|eot_id|>\")[-1]\n",
    "outputs = output.replace(eos_c_token, '')\n",
    "\n",
    "citation_prompt =  citation_extract_prompt_add(results, doc_1, doc_2, doc_3)\n",
    "\n",
    "imsi_error = \"<|start_header_id|>system<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
    "outputs = outputs.replace(imsi_error, '')\n",
    "outputs_ex = outputs + '\\n\\n' + citation_prompt\n",
    "\n",
    "print('[user msg] = ', query_text)\n",
    "print()\n",
    "print('[AI bot msg] = ', outputs_ex) # outputs_ex\n",
    "\n",
    "\n",
    "print(\"time :\", time.time() - start)  # 현재시각 - 시작시간 = 실행 시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b226c0-8bb8-44df-a30f-a7aa56bfdffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb874c-a00a-4312-9c42-dea71b9a44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 밑에는 다른 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8413dbfe-f4a8-4a2e-9781-45f7abe8a7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e509450-30df-40be-86dd-c8a4e90db491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f2c96-d6a8-4cb0-b88f-27f0f7b360cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3024e-f3f4-480e-b7a1-7d0768eaf962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f809cc-c299-47f9-bf48-a8ad25f84632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74efa63-195f-40b7-a8f0-7e734572550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LLAMA.CPP CPU 용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03a12f33-1888-4390-8c12-2f45a974d7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 25 key-value pairs and 435 tensors from ./models/EEVE-Korean-Instruct-10.8B-q4_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                           llama.vocab_size u32              = 40960\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                          llama.block_count u32              = 48\n",
      "llama_model_loader: - kv   6:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   7:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  11:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  12:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.tokens arr[str,40960]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.scores arr[f32,40960]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,40960]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 2\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  22:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   97 tensors\n",
      "llama_model_loader: - type q4_0:  337 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 261/40960 vs 260/40960 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 40960\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 48\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 34B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 10.80 B\n",
      "llm_load_print_meta: model size       = 5.70 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 32000 '<|im_end|>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 2 '</s>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_print_meta: EOT token        = 32000 '<|im_end|>'\n",
      "llm_load_tensors: ggml ctx size =    0.44 MiB\n",
      "llm_load_tensors: offloading 1 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 1/49 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  5838.77 MiB\n",
      "llm_load_tensors:      CUDA0 buffer size =   117.03 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:  CUDA_Host KV buffer size =   376.00 MiB\n",
      "llama_kv_cache_init:      CUDA0 KV buffer size =     8.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  384.00 MiB, K (f16):  192.00 MiB, V (f16):  192.00 MiB\n",
      "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.16 MiB\n",
      "llama_new_context_with_model:      CUDA0 compute buffer size =   227.25 MiB\n",
      "llama_new_context_with_model:  CUDA_Host compute buffer size =    12.01 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1542\n",
      "llama_new_context_with_model: graph splits = 521\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.name': 'LLaMA v2', 'general.architecture': 'llama', 'llama.block_count': '48', 'llama.vocab_size': '40960', 'llama.context_length': '4096', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '32000', 'general.file_type': '2', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.padding_token_id': '2', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.chat_template': \"{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = 'You are a helpful assistant.' %}{% endif %}{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 %}{{'<|im_start|>system\\n' + system_message + '<|im_end|>\\n'}}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"}\n",
      "Using gguf chat template: {% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = 'You are a helpful assistant.' %}{% endif %}{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in loop_messages %}{% if loop.index0 == 0 %}{{'<|im_start|>system\n",
      "' + system_message + '<|im_end|>\n",
      "'}}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "Using chat eos_token: <|im_end|>\n",
      "Using chat bos_token: <s>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "model_name = \"./models/EEVE-Korean-Instruct-10.8B-q4_0.gguf\"\n",
    "\n",
    "llm = Llama(\n",
    "      model_path=model_name,\n",
    "      n_gpu_layers= 1, # Uncomment to use GPU acceleration   -1, 0~  \n",
    "      #seed=1337, # Uncomment to set a specific seed\n",
    "      n_ctx=2048, # Uncomment to increase the context window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0224511-519e-4cda-af50-70db4aaea315",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 입력 텍스트 설정\n",
    "#prompt = \"Hello, how are you?\"\n",
    "\n",
    "# 모델 실행\n",
    "output = llm(\n",
    "      prompt, # Prompt\n",
    "      max_tokens=2048, # Generate up to 32 tokens, set to None to generate up to the end of the context window\n",
    "      #stop=[\"Q:\", \"\\n\"], # Stop generating just before the model would generate a new question\n",
    "      stop=['<|im_end|>'], #, '## summary', '\\n\\n'],\n",
    "      #top_k = 30 ,\n",
    "      top_p= 0.85 ,\n",
    "      temperature= 0.8,\n",
    "      echo= False # Echo the prompt back in the output\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Output:\", output)\n",
    "print()\n",
    "# 실행할 코드 블록 끝 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 실행 시간 계산 및 출력\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution Time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f9005-55d6-40dc-ac6c-a0d4e75baa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['choices'][0]['text'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c290f-68c9-4a85-9908-819d9226750c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e468b7-a44b-4ba1-8a5e-6844f9e50897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f27871f1-ce9f-4070-9303-d18cd44a5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 벡터 임베딩 : gpt \n",
    "class MyOpenAIEmbeddingFunction:\n",
    "    def __init__(self):\n",
    "        self.model_name = \"text-embedding-ada-002\"\n",
    "\n",
    "    def __call__(self, input):\n",
    "        if isinstance(input, str):\n",
    "            input = [input]  # Ensure the input is in list form\n",
    "        \n",
    "        embeddings = []\n",
    "        for text in input:\n",
    "            # API call to get embeddings for each text in the list\n",
    "            response = openai.Embedding.create(\n",
    "                model=self.model_name,\n",
    "                input=text\n",
    "            )\n",
    "            # Extract and append the embedding from the response\n",
    "            embeddings.append(response['data'][0]['embedding'])\n",
    "        \n",
    "        return embeddings\n",
    "# Instantiate the embedding function\n",
    "embedding_function = MyOpenAIEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8bc14fc-de43-4776-8ccb-c7c814bc27df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin C:\\Users\\any\\anaconda3\\envs\\oosij\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a0549c9b0141cba7ba9195c7e9c9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------using 4*GPUs----------\n"
     ]
    }
   ],
   "source": [
    "## 벡터 임베딩 \n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "import numpy as np\n",
    "\n",
    "class MyEmbeddingFunction:\n",
    "    def __init__(self):\n",
    "        self.model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)\n",
    "\n",
    "    def __call__(self, input):\n",
    "        if isinstance(input, str):\n",
    "            input = [input]\n",
    "        # Encode the input text\n",
    "        embeddings = self.model.encode(input, \n",
    "                                       batch_size=12, \n",
    "                                       max_length= 4096)['dense_vecs']\n",
    "        return embeddings\n",
    "\n",
    "# Instantiate the embedding function\n",
    "embedding_function = MyEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03650e84-0d47-4bc7-96e1-d95d06d6a670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fb185680ad4178a709a95fb9e3e832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 로컬 모델\n",
    "#### 개인 라마 3 inst 버전 \n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#torch.set_default_device('cuda')\n",
    "device_map = 'auto'\n",
    "#model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "model_id  = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\"\n",
    "#model_id = \"beomi/llama-2-ko-7b\"\n",
    "#model_id = \"kfkas/Llama-2-ko-7b-Chat\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,)\n",
    "\n",
    "#model.eval()\n",
    "#model.config.use_cache = (True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, torch_dtype=torch.bfloat16)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "#tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58a2bbb-fa3a-4c47-80cd-bddb20f596fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc77d0-04a0-4dbe-b8ce-bf4a2704c3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b820b33-0f54-42bb-9680-1e271200f5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "422e480d-c866-4829-94c5-d2f7ac46f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의로 만든 인용 추출기\n",
    "def citation_extract_prompt_add(results, doc_1, doc_2, doc_3):\n",
    "    doc_1_c = citation_extarct(results, doc_1)\n",
    "    doc_2_c =citation_extarct(results, doc_2)\n",
    "    doc_3_c = citation_extarct(results, doc_3)\n",
    "\n",
    "    cp_path_1, sp_1, ep_1 = doc_citation_extract(doc_1_c)\n",
    "    cp_path_2, sp_2, ep_2 = doc_citation_extract(doc_2_c)\n",
    "    cp_path_3, sp_3, ep_3 = doc_citation_extract(doc_3_c)\n",
    "\n",
    "\n",
    "    citation_template = \"\"\"이 답변은 다음 증권사 리포트 파일을 인용해서 가져왔습니다 :\n",
    "- {citation_pdf_path_1} 파일의 본문 길이 : {start_page_1}에서 {end_page_1}까지 인용\n",
    "- {citation_pdf_path_2} 파일의 본문 길이 : {start_page_2}에서 {end_page_2}까지 인용\n",
    "- {citation_pdf_path_3} 파일의 본문 길이 : {start_page_3}에서 {end_page_3}까지 인용\"\"\"\n",
    "\n",
    "    citation_prompt = citation_template.format(citation_pdf_path_1 = cp_path_1 , citation_pdf_path_2 = cp_path_2, citation_pdf_path_3 = cp_path_3 ,\n",
    "                                          start_page_1 = sp_1 , start_page_2 =  sp_2, start_page_3 = sp_3 ,\n",
    "                                          end_page_1 = ep_1 , end_page_2 = ep_2, end_page_3 = ep_3 )\n",
    "    return citation_prompt\n",
    "\n",
    "def citation_extarct(results, doc_n):\n",
    "    check_list = results['documents'][0]\n",
    "    metas_list = results['metadatas'][0]\n",
    "\n",
    "    ok_list = []\n",
    "\n",
    "    for r in range(len(check_list)):\n",
    "        snippet = check_list[r]\n",
    "        if doc_n in snippet:\n",
    "            cit = metas_list[r]['citation']\n",
    "            p_p = metas_list[r]['pdf']\n",
    "        \n",
    "            ok_list.append([cit, p_p])\n",
    "    return ok_list\n",
    "\n",
    "def doc_citation_extract(doc_n_c):\n",
    "    dict_str = doc_n_c[0][0]\n",
    "    # ast.literal_eval을 사용하여 문자열을 딕셔너리로 변환\n",
    "    dict_obj = ast.literal_eval(dict_str)\n",
    "    dict_obj['start_p'], dict_obj['end_p']\n",
    "\n",
    "    citation_pdf_path = doc_n_c[0][1].split('\\\\')[-1] # 경로 \n",
    "\n",
    "    return citation_pdf_path, dict_obj['start_p'], dict_obj['end_p']\n",
    "\n",
    "def inference_output(prompt):\n",
    "    terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "    #input_ids = tokenizer.apply_chat_template(messages,add_generation_prompt=True,return_tensors=\"pt\").to(model.device)\n",
    "    # 인퍼런스 커스텀\n",
    "    #inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).to(\"cuda\") # return_token_type_ids=False\n",
    "    # peft 일시, **tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False) 아래 inputs['input_ids'] 교체 , 위는 삭제 \n",
    "    output = model.generate(\n",
    "        **tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False),\n",
    "        max_new_tokens = 1024, # 200  256 512\n",
    "        do_sample= True, # temperature 매개변수는 top_p 및 top_k와 함께 do_sample=True일 때만 활성화\n",
    "        top_p= 0.92,# 누적 확률을 기준으로 역순으로 단어를 정렬, 지정한 값에 도달하는 순간 멈춤 (단어 선별, 확률 분포의 긴꼬리를 자름 -> 자연스러운 텍스트 생성)\n",
    "        top_k=20, # 특별한 이유없으면 1로 지정 , top_p와 다르게 누적 건수를 기준으로 선별 \n",
    "        no_repeat_ngram_size=3,\n",
    "        temperature= 0.3, # 0.37,\n",
    "        early_stopping= True,\n",
    "        eos_token_id=terminators,  # 종료 토큰 지정 : 2 = </s> ,   46332 =  <|endoftext|>\n",
    "        repetition_penalty=1.2,\n",
    "        #pad_token_id= tokenizer.eos_token_id,\n",
    "        #eos_token_id= tokenizer.eos_token_id,\n",
    "        num_beams=3,\n",
    "    )\n",
    "    output = output[0].to(\"cpu\")\n",
    "    return tokenizer.decode(output)\n",
    "\n",
    "# Document 클래스 정의\n",
    "class Document:\n",
    "    def __init__(self, page_content, metadata):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Document(page_content={self.page_content}, metadata={self.metadata})\"\n",
    "\n",
    "# 텍스트를 일정한 크기로 나누고 오버랩하는 클래스\n",
    "class CharacterTextSplitter:\n",
    "    def __init__(self, chunk_size, chunk_overlap, separator=''):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.separator = separator\n",
    "\n",
    "    def split_text(self, text):\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        while start < len(text):\n",
    "            end = min(start + self.chunk_size, len(text))\n",
    "            if self.separator:\n",
    "                end = text.find(self.separator, start, end)\n",
    "                if end == -1:\n",
    "                    end = min(start + self.chunk_size, len(text))\n",
    "                else:\n",
    "                    end += len(self.separator)\n",
    "            chunk = text[start:end]\n",
    "            chunks.append((chunk, start, end - 1))\n",
    "            start += self.chunk_size - self.chunk_overlap\n",
    "        return chunks\n",
    "\n",
    "    def split_documents(self, documents):\n",
    "        split_docs = []\n",
    "        for doc in documents:\n",
    "            text_chunks = self.split_text(doc.page_content)\n",
    "            for chunk, start_p, end_p in text_chunks:\n",
    "                # 메타데이터에 citation 정보 추가\n",
    "                metadata_with_citation = {**doc.metadata, 'citation': {'start_p': start_p, 'end_p': end_p}}\n",
    "                split_docs.append(Document(page_content=chunk, metadata=metadata_with_citation))\n",
    "        return split_docs\n",
    "\n",
    "\n",
    "def timestamp_convert(documents): # datetime string\n",
    "    key_add = 'timestamp'\n",
    "    for doc in documents:\n",
    "        datetime_object = doc.metadata['wdate']\n",
    "        if isinstance(datetime_object, str):\n",
    "            # wdate가 문자열인 경우, datetime 객체로 변환\n",
    "            datetime_object = datetime.strptime(datetime_object, \"%Y-%m-%d %H:%M:%S\")\n",
    "        timestamp = int(datetime_object.timestamp())\n",
    "        doc.metadata[key_add] = timestamp\n",
    "        doc.metadata['wdate'] = str(datetime_object)  # datetime 객체를 str로 변환\n",
    "    return documents\n",
    "\n",
    "# reranker model load\n",
    "def reranker_model(query_text, doc_n):\n",
    "    def exp_normalize(x):\n",
    "        b = x.max()\n",
    "        y = np.exp(x - b)\n",
    "        return y / y.sum()\n",
    "    \n",
    "    rmodel_path = 'Dongjin-kr/ko-reranker'\n",
    "\n",
    "    rtokenizer = AutoTokenizer.from_pretrained(rmodel_path)\n",
    "    rmodel = AutoModelForSequenceClassification.from_pretrained(rmodel_path)\n",
    "    rmodel.eval()\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    for i in range(len(doc_n)):\n",
    "        docs = doc_n[i]\n",
    "        query_doc = [query_text, docs ]\n",
    "        pairs.append(query_doc)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = rtokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "        scores = rmodel(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "        scores = exp_normalize(scores.numpy())\n",
    "        #print (f'first: {scores[0]}, second: {scores[1]}')\n",
    "    sorted_indices = np.argsort(-scores)\n",
    "    sorted_values = scores[sorted_indices]\n",
    "\n",
    "    index_numbers = sorted_indices[:3]\n",
    "\n",
    "    sent_list = []\n",
    "\n",
    "    for d in range(len(index_numbers)):\n",
    "        index_n = index_numbers[d]\n",
    "        sent = doc_n[index_n]\n",
    "        #print(sent)\n",
    "        sent_list.append(sent)\n",
    "    return sent_list\n",
    "\n",
    "## 함수 추가 \n",
    "\n",
    "# 패턴이 동일하면 할 날짜 \n",
    "def file_date_format(file_path):\n",
    "    # 정규 표현식을 사용하여 날짜 추출\n",
    "    date_string = re.search(r'\\d{6}', file_path).group()\n",
    "\n",
    "    # 문자열을 datetime 객체로 변환\n",
    "    date_object = datetime.strptime(date_string, '%Y%m%d')\n",
    "    \n",
    "    return date_object\n",
    "\n",
    "\n",
    "# 표 데이터 제거\n",
    "def remove_table_data(text):\n",
    "    # 숫자와 기호로 이루어진 표 패턴 탐지 및 제거\n",
    "    table_pattern = re.compile(r'(\\d{1,3}(?:,\\d{3})*(?:\\.\\d+)?(?:[\\%\\원억십조천백]*)?\\s*)+', re.MULTILINE)\n",
    "    cleaned_text = re.sub(table_pattern, '', text)\n",
    "    \n",
    "    # '표' 또는 'Fig'가 들어간 줄 제거\n",
    "    cleaned_text = re.sub(r'표\\d+.*|Fig\\.\\s*\\d+.*', '', cleaned_text)\n",
    "    \n",
    "    # 추가적으로 다중 공백, 특수 문자 정리\n",
    "    cleaned_text = re.sub(r'\\n\\s*\\n', '\\n', cleaned_text)  # 다중 공백을 한 줄로 정리\n",
    "    cleaned_text = re.sub(r'[^\\S\\r\\n]+', ' ', cleaned_text)  # 다중 공백을 한 칸 공백으로 정리\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # 연속된 공백을 한 칸 공백으로 정리\n",
    "    cleaned_text = re.sub(r'\\n+', '\\n', cleaned_text)  # 연속된 줄 바꿈을 한 줄로 정리\n",
    "    cleaned_text = re.sub(r'[ ]*표[ ]*\\d+', '', cleaned_text)  # '표'와 숫자가 포함된 문자열 제거\n",
    "    cleaned_text = re.sub(r'Fig[ ]*\\d+', '', cleaned_text)  # 'Fig'와 숫자가 포함된 문자열 제거\n",
    "    cleaned_text = remove_specific_pattern(cleaned_text)\n",
    "    \n",
    "\n",
    "# 특정 패턴 제거 함수\n",
    "def remove_specific_pattern(text):\n",
    "    # 텍스트 내의 특정 패턴을 정의하고 제거\n",
    "    specific_pattern = re.compile(r'\\n\\(천 원 \\)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\(십 억 원 \\)\\n\\n\\n\\n\\n\\n\\(\\)\\n\\(\\)\\n\\(\\)\\n\\n\\n\\n\\n\\n\\n주\\n\\n\\n\\n가\\n\\.X\\n\\n\\n\\n영\\n\\n\\n\\n업\\n\\n\\n\\n현\\n\\n\\n\\n금\\n\\n\\.X\\n\\.X\\n\\n흐 름\\n\\n\\n\\n\\n\\n\\.X\\n\\.X\\n\\n\\n\\n\\n\\n\\n\\(천 원\\n\\n\\n\\n\\n\\n\\n\\n\\(십 억\\n,\\n,\\n,\\n,\\n\\n\\)\\n\\n원\\n\\n\\n\\n\\n\\n\\n\\n\\)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n주\\n\\n가\\nX\\n\\n\\n\\n\\nX\\nX\\n\\nC a p e x\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nX\\nX\\n\\n\\n\\n\\n\\n\\n\\(십억원\\) \\(십억원\\)\\nFree Cash Flow 순차입금\\n\\n\\n\\n\\n\\(\\) \\n\\n\\(\\) \\n\\n\\(\\)\\n\\n\\(\\) \\(\\)\\n\\n재무상태표 포괄손익계산서\\n \\n \\n \\n \\n 률 \\n비 \\n \\n \\n 률 \\n \\n ---\\n ----\\n -\\n비 기타 --\\n -\\n 률 -\\n -\\n \\n \\n \\n 률 \\n \\n -\\n현금흐름표 주요투자지표\\n \\n --\\n \\n \\n \\n -----\\n ----\\n감소 ----\\n감소 -----\\n증가 EV/ \\n -----\\n -----\\n증가 -----증가율 \\n감소 증가율 -\\n순감 ----\\n --\\n \\n \\n -----/자기자본 \\n -\\n \\n ------\\n', re.MULTILINE)\n",
    "    cleaned_text = re.sub(specific_pattern, '', text)\n",
    "    \n",
    "    return cleaned_text\n",
    "    \n",
    "def clean_text_by_pdf(text):\n",
    "    # 정규식을 이용해 표를 제거\n",
    "    clean_text = re.sub(r\"\\n주.*\\n\", \"\\n\", text)  # '주:'로 시작하는 줄 제거\n",
    "    clean_text = re.sub(r\"\\n\\s*PER.*\\n\", \"\\n\", clean_text)  # 'PER'로 시작하는 줄 제거\n",
    "    clean_text = re.sub(r\"\\d{4} \\d{4} \\d{4} \\d{4}\", \"\", clean_text)  # 연도별 데이터 줄 제거\n",
    "    #clean_text = re.sub(r'(?<=[가-힣])\\\\n(?=[가-힣])', '', clean_text)\n",
    "    #clean_text = re.sub(r'(?<=[가-힣])\\n(?=[가-힣])', '', clean_text)\n",
    "    clean_text = clean_text.replace('\\\\n\\\\n','')\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def prompt_clean_pdf_content(pdf_text, model_name):\n",
    "    p_template = \"\"\"pdf 파일의 내용을 텍스트 추출기를 통해 추출한 내용을 전처리 하십시오. 다음 지침을 충실히 따르십시오.\n",
    "    - \"다음은 테이블과 이미지 관련 내용을 제외한 텍스트 내용입니다:\" 와 같은 서두는 하지말아야 합니다.\n",
    "    - 매출전표, 재무재표와 같은 표로 구성된 텍스트는 제외해주세요.\n",
    "    -  ■■■■■ 이렇게 붙은 텍스트 행도 표로 간주하고 제외해주세요.\n",
    "\n",
    "    ### 삭제해야할 숫자 포함 표 텍스트 행 :\n",
    "    매출액 3,302 4,760 4,619 6,040 8,457 유동자산 2,038 2,412 2,400 3,516 2,825\n",
    "\n",
    "    매출원가 2,967 4,503 4,215 5,527 7,738 현금및현금성자산 281 390 310 1,284 118\n",
    "        \n",
    "    매출총이익 335 257 405 513 719 매출채권 및 기타채권 292 770 778 855 1,069\n",
    "\n",
    "    {pdf_text}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = p_template.format(pdf_text = pdf_text)\n",
    "\n",
    "    result = get_completion(prompt, model_name, temperature=0, verbose=False)\n",
    "    return result\n",
    "\n",
    "#pdf_text\n",
    "#text  = clean_text_by_pdf(pdf_text)\n",
    "\n",
    "# 결과 출력\n",
    "#print(text)\n",
    "\n",
    "def prompt_template_news(ticker, title, body):\n",
    "    prompt_template = \"\"\"Based on the following news article, please come up with one of the most important questions that average investors would ask.\n",
    "only answer is query. \n",
    "\n",
    "# news article : \n",
    "- ticker : \n",
    "{ticker}\n",
    "\n",
    "- article title : \n",
    "{title}\n",
    "\n",
    "- article content : \n",
    "{body}\n",
    "\n",
    "\n",
    "# query generate : \"\"\"\n",
    "    prompt_insert = prompt_template.format(ticker = ticker, title = title, body = body)\n",
    "    \n",
    "    return prompt_insert\n",
    "\n",
    "\n",
    "# 텍스트를 임베딩으로 변환하는 함수 정의\n",
    "def embed_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings.squeeze().tolist()\n",
    "\n",
    "# error, retry 추가\n",
    "def get_completion(prompt, model, temperature=0, verbose=False):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    time_start = time.time()\n",
    "    retry_count = 3\n",
    "    for i in range(0, retry_count):\n",
    "        while True:\n",
    "            try:    \n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=temperature, # this is the degree of randomness of the model's output\n",
    "                )\n",
    "                answer = response['choices'][0]['message']['content'].strip()                \n",
    "                tokens = response.usage.total_tokens                \n",
    "                \n",
    "                \n",
    "                time_end = time.time()\n",
    "                \n",
    "                if verbose:\n",
    "                    print('prompt: %s | token: %d | %.1fsec\\nanwer : %s'%(prompt, tokens, (time_end - time_start), answer))\n",
    "                return answer\n",
    "            \n",
    "            except Exception as error:\n",
    "                print(f\"API Error: {error}\")\n",
    "                print(f\"Retrying {i+1} time(s) in 4 seconds...\")\n",
    "                \n",
    "                if i+1 == retry_count:\n",
    "                    return prompt, None, None\n",
    "                time.sleep(4)\n",
    "                continue\n",
    "                \n",
    "def target_date_select(target_date):\n",
    "    if target_date.find(',') >= 0 :\n",
    "        td_list = target_date.split(',')\n",
    "    else:\n",
    "        td_list = [target_date.strip()]\n",
    "    return td_list \n",
    "\n",
    "def target_datetime_extract(date_range_string, data):\n",
    "    date_range_string = date_range_string.strip()\n",
    "    start_date_str, end_date_str = date_range_string.split(\"~\")\n",
    "\n",
    "    start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "\n",
    "    target_date_data = [\n",
    "        item for item in data if start_date.date() <= item[3].date() < end_date.date()\n",
    "    ]\n",
    "    return target_date_data\n",
    "\n",
    "def oracle_news_load(code):\n",
    "    sql = \"\"\"\n",
    "    SELECT A.SN, TITLE, CONTENT, WDATE, FILENAME FROM\n",
    "\n",
    "    (SELECT * FROM NEWS_VIEW WHERE CODES = '\"\"\"+code+\"\"\"' AND SOURCE ='10' AND  ROWNUM <= 10000) A, \n",
    "\n",
    "    (SELECT * FROM NEWS_CONT)B\n",
    "\n",
    "    WHERE A.SN = B.SN ORDER BY SN DESC \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    # 결과 레코드를 차례대로 리스트에 저장\n",
    "    result_list = []\n",
    "    for row in cursor:\n",
    "        result_list.append(row)\n",
    "        \n",
    "    return result_list\n",
    "\n",
    "## 문장 분리기 : 31 이하 단어 수는 삭제 (불필요한 짧은 문장 제거)\n",
    "def body_split_token(text):\n",
    "    #kkma = Kkma()\n",
    "    #token_sentence = kkma.sentences(text)\n",
    "    token_sentence =  split_sentences(text)\n",
    "    doc_token_list = []\n",
    "\n",
    "    for t in range(len(token_sentence)): \n",
    "        doc_token = token_sentence[t]\n",
    "        doc_token = re.sub('&nbsp-','', doc_token)\n",
    "        if len(doc_token) <= 31:\n",
    "            continue\n",
    "\n",
    "        doc_token_list.append(doc_token)\n",
    "        \n",
    "    return doc_token_list\n",
    "\n",
    "\n",
    "def oracle_sql_select(code):\n",
    "    sql = \"\"\"\n",
    "    SELECT A.SN, TITLE, CONTENT FROM\n",
    "\n",
    "    (SELECT * FROM NEWS_VIEW WHERE CODES = '\"\"\"+code+\"\"\"' AND SOURCE ='10' AND  ROWNUM <= 1000) A, \n",
    "\n",
    "    (SELECT * FROM NEWS_CONT)B\n",
    "\n",
    "    WHERE A.SN = B.SN ORDER BY SN DESC \n",
    "\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    \n",
    "    # 결과 레코드를 차례대로 리스트에 저장\n",
    "    result_list = []\n",
    "    for row in cursor:\n",
    "        result_list.append(row)\n",
    "        \n",
    "    return result_list\n",
    "\n",
    "def sql_output_data(result_list, code):\n",
    "    news_list = []\n",
    "\n",
    "    for r in range(len(result_list)):\n",
    "        index_number = result_list[r][0]\n",
    "        title = result_list[r][1].strip()\n",
    "        body_origin = result_list[r][2].read()\n",
    "        soup = BeautifulSoup(body_origin, 'html.parser')\n",
    "        text_body = soup.find_all('p')\n",
    "        if len(text_body) <= 0:\n",
    "            body = body_origin\n",
    "        else:\n",
    "            # BeautifulSoup을 사용하여 HTML 파싱\n",
    "            body = body_html_del(body_origin)\n",
    "            # BeautifulSoup을 사용하여 HTML 파싱\n",
    "        http_only_check = http_url_search(body)\n",
    "        if http_only_check == True:  # 링크들만 있으면 스킵\n",
    "            continue\n",
    "        if len(body) ==0:\n",
    "            continue\n",
    "        ndata = [index_number, code, title, body]\n",
    "        news_list.append(ndata)\n",
    "        \n",
    "    return news_list\n",
    "\n",
    "## 함수 만들기 \n",
    "\n",
    "def body_html_del(body_origin):\n",
    "    soup = BeautifulSoup(body_origin, 'html.parser')\n",
    "    text_body = soup.find_all('p')\n",
    "    body_p = ''\n",
    "    for b in range(len(text_body)):\n",
    "        tbody = text_body[b].text\n",
    "        tbody = tbody.replace('\\xa0','')\n",
    "        body_kor_check = contains_korean(tbody)\n",
    "\n",
    "        if body_kor_check == False:  # 링크들만 있으면 스킵\n",
    "            continue\n",
    "        if b == 0:\n",
    "            body_p = tbody\n",
    "        else:\n",
    "            body_p = body_p +' '+ tbody\n",
    "        \n",
    "    return body_p\n",
    "\n",
    "# 본문 http url 링크만 있는 경우 탐지 \n",
    "def http_url_search(text):\n",
    "    pattern = r'http\\S+'\n",
    "    find_url = re.compile(pattern)\n",
    "    \n",
    "    return  bool(find_url.search(text))\n",
    "\n",
    "\n",
    "### 여기는 전처리 후보인데, 현재는 사용하지 않음 \n",
    "## 본문 전처리 1\n",
    "def body_preprocessing(body):\n",
    "    # 정규식을 사용해 불필요한 태그 제거\n",
    "    text = re.sub('<.*?>', '', body)\n",
    "    # [숫자] 패턴 제거\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "    # [문자열] 패턴 제거\n",
    "    text = re.sub(r'\\[[^\\]]+\\]', '', text)\n",
    "    return text\n",
    "\n",
    "## 한글 체크하기 \n",
    "def contains_korean(text):\n",
    "    korean = re.compile('[ㄱ-ㅣ가-힣]+')\n",
    "    return bool(korean.search(text))\n",
    "\n",
    "# 본문 http url 링크 삭제하기 \n",
    "def text_http_del(text):\n",
    "    pattern = r'http\\S+'\n",
    "    text_without_urls = re.sub(pattern, '', text)\n",
    "    \n",
    "    return text_without_urls\n",
    "\n",
    "\n",
    "def extract_text_from_html(html):\n",
    "    # HTML 태그 제거\n",
    "    html = re.sub(r'<[^>]*>', '', html)\n",
    "    \n",
    "    # CSS 스타일 태그 제거\n",
    "    html = re.sub(r'<style.*>.*<\\/style>', '', html, flags=re.DOTALL)\n",
    "    \n",
    "    # 불필요한 공백 문자 제거\n",
    "    html = re.sub(r'\\s+', ' ', html)\n",
    "    \n",
    "    # 텍스트 추출\n",
    "    text = html.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def extract_korean(text):\n",
    "    korean_pattern = re.compile('[^ㄱ-ㅣ가-힣]+')\n",
    "    korean_text = korean_pattern.sub(' ', text)\n",
    "    return korean_text\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "# 뉴스 본문 정규표현식 전처리 모듈 : 기자 나누기 \n",
    "def newsbody_preprocessing(body):\n",
    "    text_filter = re.compile('[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9&,\\.\\?\\!\\\"\\'-()\\[\\]\\{\\}]')\n",
    "    email_pattern = re.compile('^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$')\n",
    "    reporter_pattern = re.compile('[가-힣]{2,4},\\s?[가-힣]{2,4}\\s?기자|([가-힣]{2,4})\\s?기자')\n",
    "    doublespace_pattern = re.compile('\\s+')\n",
    "    \n",
    "    text = email_pattern.sub(' ', body)\n",
    "    reporter = reporter_pattern.search(text)\n",
    "    if reporter != None:\n",
    "        reporter = reporter.group(0)\n",
    "    # text = reporter_pattern.sub(' ', text)\n",
    "    text = text_filter.sub(' ', text)\n",
    "    text = doublespace_pattern.sub(' ', text).strip()\n",
    "    text = text.split(reporter)\n",
    "    text = text[0]\n",
    "    return text, reporter\n",
    "\n",
    "## pdf 로더 \n",
    "def extract_text_images_tables(pdf_path):\n",
    "    all_text = \"\"\n",
    "    images = []\n",
    "    tables = []\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extract text\n",
    "            all_text += page.extract_text() + \"\\n\"\n",
    "\n",
    "            # Extract images\n",
    "            for image in page.images:\n",
    "                images.append(image)\n",
    "\n",
    "            # Extract tables\n",
    "            for table in page.extract_tables():\n",
    "                tables.append(table)\n",
    "    \n",
    "    return all_text, images, tables\n",
    "\n",
    "\n",
    "def extract_text_without_tables_images(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extracting raw text from the page\n",
    "            page_text = page.extract_text()\n",
    "            \n",
    "            if page_text is None:\n",
    "                continue\n",
    "            \n",
    "            # Extracting tables from the page\n",
    "            tables = page.extract_tables()\n",
    "\n",
    "            # Filter out text that belongs to tables\n",
    "            if tables:\n",
    "                for table in tables:\n",
    "                    for row in table:\n",
    "                        for cell in row:\n",
    "                            if cell is not None:\n",
    "                                page_text = page_text.replace(cell, '')\n",
    "\n",
    "            # Adding the cleaned page text to the final text\n",
    "            text += page_text + \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "def pdf_loader(pdf_path):\n",
    "    #pdf_path ='./data/삼성전자샘플_005930.pdf'\n",
    "    # Extract text, images, and tables from the PDF\n",
    "    extracted_text = extract_text_without_tables_images(pdf_path)\n",
    "    # image / table can't\n",
    "\n",
    "    # Print the extracted text\n",
    "    pdf_text = repr(extracted_text)\n",
    "    \n",
    "    return pdf_text\n",
    "\n",
    "def get_pdf_paths(folder_path):\n",
    "\n",
    "    pdf_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_paths.append(os.path.join(root, file))\n",
    "    return pdf_paths\n",
    "\n",
    "def pdf_loader_by_folder(data_folder_path):\n",
    "    pdf_files = get_pdf_paths(data_folder_path)\n",
    "                         \n",
    "    page_list = []\n",
    "\n",
    "    for p in range(len(pdf_files)):\n",
    "        pdf_path = pdf_files[p]\n",
    "        page = pdf_loader(pdf_path)\n",
    "        page_list.append(page)\n",
    "    return page_list, pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51c4d7e-51a8-4d00-a86b-80137d166bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oosij",
   "language": "python",
   "name": "oosij"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
